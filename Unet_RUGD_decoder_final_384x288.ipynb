{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3974c1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3974c1a",
    "outputId": "82fe81e4-cada-4493-ae4c-1b1cdda67f88"
   },
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GBHqL87M9oKh",
   "metadata": {
    "id": "GBHqL87M9oKh"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.config.experimental.reset_memory_stats('GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0ecc45-898b-4e5b-b7cb-393aefce5984",
   "metadata": {
    "id": "9e0ecc45-898b-4e5b-b7cb-393aefce5984"
   },
   "outputs": [],
   "source": [
    "!# Define the color map\n",
    "color_map = {\n",
    "    0: [0, 0, 0],                # void\n",
    "    1: [108, 64, 20],            # dirt\n",
    "    2: [255, 229, 204],          # sand\n",
    "    3: [0, 102, 0],              # grass\n",
    "    4: [0, 255, 0],              # tree\n",
    "    5: [0, 153, 153],            # pole\n",
    "    6: [0, 128, 255],            # water\n",
    "    7: [0, 0, 255],              # sky\n",
    "    8: [255, 255, 0],            # vehicle\n",
    "    9: [255, 0, 127],            # container/generic-object\n",
    "    10: [64, 64, 64],            # asphalt\n",
    "    11: [255, 128, 0],           # gravel\n",
    "    12: [255, 0, 0],             # building\n",
    "    13: [153, 76, 0],            # mulch\n",
    "    14: [102, 102, 0],           # rock-bed\n",
    "    15: [102, 0, 0],             # log\n",
    "    16: [0, 255, 128],           # bicycle\n",
    "    17: [204, 153, 255],         # person\n",
    "    18: [102, 0, 204],           # fence\n",
    "    19: [255, 153, 204],         # bush\n",
    "    20: [0, 102, 102],           # sign\n",
    "    21: [153, 204, 255],         # rock\n",
    "    22: [102, 255, 255],         # bridge\n",
    "    23: [101, 101, 11],          # concrete\n",
    "    24: [114, 85, 47]            # picnic-table\n",
    "}\n",
    "\n",
    "# Create a reverse lookup to map colors to class labels\n",
    "color_to_class = {tuple(value): key for key, value in color_map.items()}\n",
    "\n",
    "def color_to_class_label(mask):\n",
    "    # Convert mask to a 2D array where each pixel value is represented by an RGB tuple\n",
    "    mask_rgb = mask.reshape(-1, 3)  # Reshape to a 2D array where each row is an RGB pixel\n",
    "\n",
    "    # Map RGB values to class labels\n",
    "    label_mask = np.array([color_to_class.get(tuple(rgb), 0) for rgb in mask_rgb])\n",
    "\n",
    "    # Reshape back to the original mask shape (height, width)\n",
    "    label_mask = label_mask.reshape(mask.shape[0], mask.shape[1])\n",
    "\n",
    "    return label_mask\n",
    "\n",
    "# def color_to_class_label(mask):\n",
    "#     # Create an empty label mask\n",
    "#     label_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int32)  # Use np.int32 instead of np.long\n",
    "\n",
    "#     # For each pixel, get the RGB value and map it to the class label\n",
    "#     for i in range(mask.shape[0]):\n",
    "#         for j in range(mask.shape[1]):\n",
    "#             rgb_value = tuple(mask[i, j])\n",
    "#             if rgb_value in color_to_class:\n",
    "#                 label_mask[i, j] = color_to_class[rgb_value]\n",
    "#             else:\n",
    "#                 label_mask[i, j] = 0  # Default to class 0 if color is not found\n",
    "\n",
    "#     return label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a0738",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f1a0738",
    "outputId": "76fed580-f218-4784-ba7e-1b3534507650"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "IMG_DIR = \"./content/RUGD_frames\"\n",
    "MASK_DIR = \"./content/RUGD_annotations\"\n",
    "\n",
    "IMG_SIZE = (384, 288)\n",
    "NUM_CLASSES = 25  # Cityscapes has 19 semantic classes\n",
    "BATCH_SIZE = 8  # Reduce batch size if kernel still crashes\n",
    "\n",
    "\n",
    "# üîπ **Get List of Files & Split Data**\n",
    "def get_data_splits(test_size=0.1, val_size=0.1):\n",
    "    img_files = []\n",
    "\n",
    "    for root, _, files in os.walk(IMG_DIR):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                img_files.append(os.path.join(root, file))\n",
    "\n",
    "    img_files.sort()  # Ensure consistency\n",
    "    np.random.shuffle(img_files)  # Shuffle dataset\n",
    "\n",
    "    # Split into train, validation, and test\n",
    "    train_files, test_files = train_test_split(img_files, test_size=test_size, random_state=42)\n",
    "    train_files, val_files = train_test_split(train_files, test_size=val_size / (1 - test_size), random_state=42)\n",
    "\n",
    "    return train_files, val_files, test_files\n",
    "\n",
    "# üîπ **Function to Load Single Image**\n",
    "def load_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, IMG_SIZE)\n",
    "    img = img / 255.0  # Normalize\n",
    "    return img\n",
    "\n",
    "# üîπ **Function to Load Single Mask**\n",
    "def load_mask(mask_path):\n",
    "    mask = cv2.imread(mask_path)\n",
    "    mask_resized = cv2.resize(mask, IMG_SIZE, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    label_mask = color_to_class_label(mask_resized)\n",
    "\n",
    "    return label_mask.astype(np.int32)  # Keep as integers (not one-hot)\n",
    "\n",
    "# üîπ **Dataset Generator**\n",
    "def rugd_generator(file_list):\n",
    "    for img_path in file_list:\n",
    "        mask_path = os.path.join(MASK_DIR, os.path.relpath(img_path, IMG_DIR))\n",
    "\n",
    "\n",
    "        # üîπ Check if files exist before processing\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"‚ö†Ô∏è Skipping - Mask file not found: {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        img = load_image(img_path)\n",
    "        mask = load_mask(mask_path)\n",
    "\n",
    "        yield img, mask\n",
    "\n",
    "\n",
    "# üîπ **Convert Generator to `tf.data.Dataset`**\n",
    "def get_rugd_dataset(file_list, batch_size=BATCH_SIZE):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: rugd_generator(file_list),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(288, 384, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(288, 384), dtype=tf.int32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)  # Optimize performance\n",
    "    return dataset\n",
    "\n",
    "# üîπ **Create Train, Validation & Test Datasets**\n",
    "train_files, val_files, test_files = get_data_splits()\n",
    "\n",
    "print(f\"Total images: {len(train_files) + len(val_files) + len(test_files)}\")\n",
    "print(f\"Train set: {len(train_files)} images\")\n",
    "print(f\"Validation set: {len(val_files)} images\")\n",
    "print(f\"Test set: {len(test_files)} images\")\n",
    "\n",
    "\n",
    "train_dataset = get_rugd_dataset(train_files)\n",
    "val_dataset = get_rugd_dataset(val_files)\n",
    "test_dataset = get_rugd_dataset(test_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac062f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e5ac062f",
    "outputId": "fb648259-6d75-4e88-b035-a297770daad5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import MeanIoU\n",
    "\n",
    "# Ensure compatibility with TensorFlow 2.x\n",
    "sm.set_framework(\"tf.keras\")\n",
    "\n",
    "# Set backbone (EfficientNet or ResNet)\n",
    "BACKBONE = \"efficientnetb3\"  # Try 'resnet50' for ResNet backbone\n",
    "\n",
    "# Load Pretrained U-Net (or PSPNet, FPN)\n",
    "model = sm.Unet(BACKBONE,\n",
    "                encoder_weights=\"imagenet\",\n",
    "                classes=25,\n",
    "                activation=\"softmax\",\n",
    "                input_shape=(288, 384, 3)\n",
    "               )\n",
    "\n",
    "# Freeze ALL layers initially\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze only the decoder and final conv layers\n",
    "for layer in model.layers:\n",
    "    if \"decoder\" in layer.name or \"final_conv\" in layer.name or \"softmax\" in layer.name:\n",
    "        layer.trainable = True  # Fine-tune decoder\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", MeanIoU(num_classes=25, sparse_y_pred=False)])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e732757",
   "metadata": {
    "id": "5e732757"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)  # Forces eager execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WcFOKzU_8YKQ",
   "metadata": {
    "id": "WcFOKzU_8YKQ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Early Stopping: Stop if val_loss doesn't improve for 5 epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Track validation loss\n",
    "    patience=2,  # Stop after 2 epochs of no improvement\n",
    "    verbose=1,\n",
    "    restore_best_weights=True  # Restore best weights\n",
    ")\n",
    "\n",
    "# Model Checkpoint: Save the best model based on validation IoU\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"best_RUGD_384x288_model_.keras\",  # File name\n",
    "    monitor=\"val_mean_io_u\",  # Track MeanIoU\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode=\"max\",  # Maximize IoU\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Add Callbacks to Training\n",
    "callbacks = [early_stopping, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53438321",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "53438321",
    "outputId": "254ece7d-e4b6-4c05-9946-690797b1f37a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=20,  # Set a high epoch limit (early stopping will stop automatically)\n",
    "    callbacks=callbacks  # Include callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187e9dd",
   "metadata": {
    "id": "3187e9dd"
   },
   "outputs": [],
   "source": [
    "# Evaluate on Test Set\n",
    "test_loss, test_acc, test_mean_iou = model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Mean IoU: {test_mean_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c02e4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50c02e4a",
    "outputId": "bf5536fe-0332-46f9-f4ca-fd707c01b36c"
   },
   "outputs": [],
   "source": [
    "# Test on a Sample Image\n",
    "for test_img, test_mask in test_dataset.take(1):  # Take first test batch\n",
    "    pred_mask = model.predict(test_img)\n",
    "    pred_mask = np.argmax(pred_mask, axis=-1)  # Convert from one-hot to class indices\n",
    "    print(\"Unique values in predicted mask:\", np.unique(pred_mask))\n",
    "    print(\"Unique values in test mask:\", np.unique(test_mask))\n",
    "    break  # Only process one batch\n",
    "\n",
    "# Convert to numpy array for easy indexing\n",
    "color_array = np.array([color_map[key] for key in sorted(color_map.keys())], dtype=np.uint8)\n",
    "\n",
    "# Function to apply color map to label mask\n",
    "def apply_color_map(label_mask):\n",
    "    \"\"\"Convert label mask (H, W) to a color image (H, W, 3).\"\"\"\n",
    "    return color_array[label_mask]\n",
    "\n",
    "# Ensure predicted mask only contains valid labels\n",
    "valid_labels = np.array(list(color_map.keys()))\n",
    "pred_mask = np.where(np.isin(pred_mask, valid_labels), pred_mask, 0)  # Map invalid classes to 0 (void)\n",
    "\n",
    "# Convert grayscale mask to color\n",
    "test_mask_color = apply_color_map(test_mask)\n",
    "pred_mask_color = apply_color_map(pred_mask)\n",
    "\n",
    "n=5\n",
    "\n",
    "# Display Results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 3, 1); plt.imshow(test_img[n]); plt.title(\"Input Image\")\n",
    "plt.subplot(1, 3, 2); plt.imshow(test_mask_color[n]); plt.title(\"Ground Truth\")\n",
    "plt.subplot(1, 3, 3); plt.imshow(pred_mask_color[n]); plt.title(\"Predicted Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1917aaf3",
   "metadata": {
    "id": "1917aaf3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
